{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d17947",
   "metadata": {},
   "source": [
    "# Введение в DL\n",
    "\n",
    "В этом ноутбуке я пару архитектур нейросетей на датасете Mnist, который подгружу из torchvision. Это введение в обучение нейросетей. Основные задачи:\n",
    "1. Понять, что и откуда нужно импортировать\n",
    "2. Написать хоть какой-то рабочий код, успешно решающий поставленную (хоть и простую) задачу\n",
    "3. Приобрести опыт в создании собственных архитектур нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dde915",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка датасета MNIST\n",
    "\n",
    "В этом ноутбуке решается задача многоклассовой классификации. Датасет состоит из пар (изображение, класс), где:\n",
    "* изображение --- чёрно-белое изображение, содержащее какую-то одну рукописную цифру (от 0 до 9)\n",
    "* класс --- целевая переменная, представляющая собой целое число от 0 до 9, соответствующее цифре на изображении"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef9c7c",
   "metadata": {},
   "source": [
    "Задачи:\n",
    "1. Загрузить датасет\n",
    "2. Проанализировать размер датасета, размерность данных\n",
    "3. Подготовить вариант датасета для подачи на вход полносвязной нейросети\n",
    "4. Также подготовить вариант датасета для подачи на вход свёрточной нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a26ad8",
   "metadata": {},
   "source": [
    "Итак, загрузим датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d26da610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "tensor_transform = transforms.ToTensor()\n",
    "\n",
    "train_set = MNIST(root='./dataset', train=True, transform=tensor_transform, download=True)\n",
    "test_set = MNIST(root='./dataset', train=False, transform=tensor_transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8f0df",
   "metadata": {},
   "source": [
    "Посмотрим на характеристики загруженного датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "066dd158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип загруженного из torchvision файла - <class 'torchvision.datasets.mnist.MNIST'>\n",
      "Размерность изображения (1, 28, 28). Его тип - <class 'torch.Tensor'>\n",
      "Тип целевой метки = <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(f'Тип загруженного из torchvision файла - {type(train_set)}')\n",
    "print(f'Размерность изображения {tuple(train_set[0][0].size())}. Его тип - {type(train_set[0][0])}')\n",
    "print(f'Тип целевой метки = {type(train_set[0][1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac5688",
   "metadata": {},
   "source": [
    "Подготовим части датасета для обучения и тестирования. Так как это самый первый ноутбук, то мы сделаем неправильную вещь: возьмём тестовую часть датасета в качестве и тестовой, и валидационной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5145d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a059e",
   "metadata": {},
   "source": [
    "## Создание и обучение полносвязной нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88ae27",
   "metadata": {},
   "source": [
    "Подготовим архитектуру полносвязной сети:\n",
    "* Для начала необходимо изменить размерность изображения, вытянув его из 4-мерного вектора размерности `(bs, 1, 28, 28)` в двумерный вектор `(bs, 28*28)`\n",
    "* После чего добавим несколько полносвязных слоёв с функциями активации LeakyReLU\n",
    "* На последнем слое вместо LeackyReLU используем Softmax, потому что решается задача задача многоклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "335e7f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # Вытянем 4-мерный вектор в 2-мерный\n",
    "        \n",
    "        # Первый скрытый слой с функцией активации\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "    \n",
    "        # Второй скрытый слой с функцией активации\n",
    "        x = self.fc2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "\n",
    "        # Третий скрытый слой с функцией активации\n",
    "        x = self.fc3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        # Выходной слой\n",
    "        x = self.fc4(x)\n",
    "        logits = F.softmax(x)\n",
    "        \n",
    "        return logits    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14fa5a7",
   "metadata": {},
   "source": [
    "Теперь напишем функцию для обучения нашей сети:\n",
    "* в качестве оптимизатора я буду использовать дефолтный Adam с `learning_rate = 3e-4`\n",
    "* так как решается задача классификации, то лосс-функцией будет кросс-энтропия\n",
    "* обучение будет длиться 20 эпох\n",
    "* на каждой эпохе будет выводиться информация о значении лосс-функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a778f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, epochs=10):\n",
    "\n",
    "    # Использование GPU, если таковая имеется\n",
    "    use_cuda = False # torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "    \n",
    "    # Настраиваю оптимизатор и лосс-функцию\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # one-epoch training\n",
    "        losses = []\n",
    "        for x, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            if use_cuda:\n",
    "                x, target = x.cuda(), target.cuda()\n",
    "            # x, target = Variable(x), Variable(target)\n",
    "            \n",
    "            predicted = model(x)\n",
    "            loss = criterion(predicted, target)\n",
    "            losses.append(loss.data)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = sum(losses) / len(losses)\n",
    "        \n",
    "        # one-epoch validation\n",
    "        losses = []\n",
    "        for x, target in valid_loader:\n",
    "            if use_cuda:\n",
    "                x, target = x.cuda(), target.cuda()\n",
    "            \n",
    "            predicted = model(x)\n",
    "            loss = criterion(predicted, target)\n",
    "            losses.append(loss.data)\n",
    "            \n",
    "        valid_loss = sum(losses) / len(losses)\n",
    "        \n",
    "        print(\"epoch{:3d}: train_loss == {:5.2f}, valid_loss == {:5.2f}\".format(epoch, train_loss, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a53631fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02031\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0: train_loss ==  1.65, valid_loss ==  1.55\n",
      "epoch  1: train_loss ==  1.54, valid_loss ==  1.53\n",
      "epoch  2: train_loss ==  1.52, valid_loss ==  1.51\n",
      "epoch  3: train_loss ==  1.51, valid_loss ==  1.51\n",
      "epoch  4: train_loss ==  1.50, valid_loss ==  1.50\n",
      "epoch  5: train_loss ==  1.49, valid_loss ==  1.50\n",
      "epoch  6: train_loss ==  1.49, valid_loss ==  1.49\n",
      "epoch  7: train_loss ==  1.49, valid_loss ==  1.49\n",
      "epoch  8: train_loss ==  1.48, valid_loss ==  1.49\n",
      "epoch  9: train_loss ==  1.48, valid_loss ==  1.49\n"
     ]
    }
   ],
   "source": [
    "model = FCNet()\n",
    "train_model(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d97867",
   "metadata": {},
   "source": [
    "Модель обучена!\n",
    "\n",
    "Теперь напишем функцию для тестирования полученной модели. В качестве оценки качества работы модели будет выступать точность классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d59ee51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, train_loader, test_loader):\n",
    "    use_cuda = False\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        \n",
    "    def calculate_accuracy(model, loader):\n",
    "        correct_n = 0\n",
    "        total_n = 0\n",
    "\n",
    "        for x, target in loader:\n",
    "            if use_cuda:\n",
    "                x, target = x.cuda(), target.cuda()\n",
    "            predicted = model(x)\n",
    "            _, predicted_labels = torch.max(predicted.data, 1)\n",
    "            total_n += target.data.size()[0]\n",
    "            correct_n += (predicted_labels == target).sum()\n",
    "        return correct_n / total_n\n",
    "    \n",
    "    train_accuracy = calculate_accuracy(model, train_loader)\n",
    "    test_accuracy = calculate_accuracy(model, test_loader)\n",
    "    \n",
    "    print(\"Total train accuracy score is {:2.2f}%\".format(train_accuracy * 100))\n",
    "    print(\"Total test accuracy score is {:2.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1e3ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02031\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train accuracy score is 98.38%\n",
      "Total test accuracy score is 97.35%\n"
     ]
    }
   ],
   "source": [
    "test_model(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b3b4b",
   "metadata": {},
   "source": [
    "Неплохие результаты! Точность классификации полносвязной модели 97.35%\n",
    "\n",
    "Попробуем теперь применить к этой задаче свёрточную архитектуру."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f606b21",
   "metadata": {},
   "source": [
    "## Создание и обучение свёрточной нейросети\n",
    "\n",
    "## TODO: сделать код этого раздела. Добиться качества выше, чем у полносвязной нейросети\n",
    "\n",
    "Особенности архитектуры:\n",
    "* Сеть разделена на блоки. Каждый блок состоит из свёрточного слоя, функции активации и аггрегационного слоя (MaxPooling)\n",
    "* После пары свёрточных блоков будет пара полносвязных слоёв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6be6ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(4*4*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Первый свёрточный блок\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        # print(x.size())\n",
    "\n",
    "        # Второй свёрточный блок\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        # print(x.size())\n",
    "        \n",
    "        # Третий свёрточный блок\n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.pool(x)\n",
    "        # print(x.size())\n",
    "\n",
    "        # Вытягивание 4-мерного тензора в 2-мерный\n",
    "        sz = x.data.size()\n",
    "        x = x.view(-1, sz[1] * sz[2] * sz[3])\n",
    "\n",
    "        # Первый полносвязный блок\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        # Второй полносвязный блок\n",
    "        x = self.fc2(x)\n",
    "        logits = F.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40802fe4",
   "metadata": {},
   "source": [
    "Обучим модель со свёрточной архитектурой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "37773f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02031\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0: train_loss ==  0.52, valid_loss ==  0.14\n",
      "epoch  1: train_loss ==  0.12, valid_loss ==  0.08\n",
      "epoch  2: train_loss ==  0.08, valid_loss ==  0.06\n",
      "epoch  3: train_loss ==  0.06, valid_loss ==  0.04\n",
      "epoch  4: train_loss ==  0.05, valid_loss ==  0.05\n",
      "epoch  5: train_loss ==  0.05, valid_loss ==  0.04\n",
      "epoch  6: train_loss ==  0.04, valid_loss ==  0.04\n",
      "epoch  7: train_loss ==  0.04, valid_loss ==  0.04\n",
      "epoch  8: train_loss ==  0.03, valid_loss ==  0.04\n",
      "epoch  9: train_loss ==  0.03, valid_loss ==  0.03\n"
     ]
    }
   ],
   "source": [
    "conv_model = ConvNet()\n",
    "train_model(conv_model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac33bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\02031\\anaconda3\\envs\\torch-cuda\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train accuracy score is 99.38%\n",
      "Total test accuracy score is 99.01%\n"
     ]
    }
   ],
   "source": [
    "test_model(conv_model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999d317",
   "metadata": {},
   "source": [
    "Отлично! Точность на тестовой выборке 99.01%, что больше почти на 2% в сравнении с полносвязной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df4ad2",
   "metadata": {},
   "source": [
    "Сравним ещё число параметров в получившихся моделях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4907cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число параметров в полносвязной сети равно 567434\n",
      "Число параметров в свёрточной сети равно   155786\n"
     ]
    }
   ],
   "source": [
    "print(\"Число параметров в полносвязной сети равно {}\".format(sum(p.numel() for p in model.parameters())))\n",
    "print(\"Число параметров в свёрточной сети равно   {}\".format(sum(p.numel() for p in conv_model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00504256",
   "metadata": {},
   "source": [
    "Получилось, что число параметров в свёрточной сети почти в 4 раза меньше, чем в полносвязной. \n",
    "\n",
    "Из этого можно сделать **вывод**: свёрточные сети позволяют решать задачи обработки изображений с привлечением меньшего числа параметров, чем полносвязные сети. \n",
    "\n",
    "В данном конкретном случае свёрточная сеть имеет более высокую точность при значительно более низком числе параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc52b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
